name: AWS Axialy Admin Deployment

on:
  workflow_dispatch:
    inputs:
      instance_identifier:
        description: "EC2 instance identifier"
        required: true
        default: "axialy-admin"
      aws_region:
        description: "AWS region (e.g. us-west-2, us-east-1)"
        default: "us-west-2"
        required: true
      instance_type:
        description: "EC2 instance type"
        default: "t3.micro"
        required: true
      domain_name:
        description: "Optional domain name for admin interface"
        required: false
        default: ""

env:
  AWS_DEFAULT_REGION: ${{ github.event.inputs.aws_region }}
  INSTANCE_IDENTIFIER: ${{ github.event.inputs.instance_identifier }}

jobs:
  prepare:
    runs-on: ubuntu-latest
    name: Prepare AWS Environment
    outputs:
      cleanup_needed: ${{ steps.check_resources.outputs.cleanup_needed }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ github.event.inputs.aws_region }}

    - name: Check for existing resources
      id: check_resources
      run: |
        echo "Checking for existing EC2 instance..."
        EXISTING_INSTANCES=$(aws ec2 describe-instances \
          --filters "Name=tag:Name,Values=${{ env.INSTANCE_IDENTIFIER }}" "Name=instance-state-name,Values=running,pending,stopping,stopped" \
          --query 'Reservations[].Instances[].InstanceId' --output text || echo "")
        
        if [ -n "$EXISTING_INSTANCES" ]; then
          echo "cleanup_needed=true" >> $GITHUB_OUTPUT
          echo "Existing instances found - cleanup will be performed"
        else
          echo "cleanup_needed=false" >> $GITHUB_OUTPUT
          echo "No existing instances found - proceeding with fresh deployment"
        fi

    - name: Cleanup existing resources
      if: steps.check_resources.outputs.cleanup_needed == 'true'
      run: |
        echo "Cleaning up existing EC2 instances..."
        EXISTING_INSTANCES=$(aws ec2 describe-instances \
          --filters "Name=tag:Name,Values=${{ env.INSTANCE_IDENTIFIER }}" "Name=instance-state-name,Values=running,pending,stopping,stopped" \
          --query 'Reservations[].Instances[].InstanceId' --output text)
        
        if [ -n "$EXISTING_INSTANCES" ]; then
          echo "Terminating instances: $EXISTING_INSTANCES"
          aws ec2 terminate-instances --instance-ids $EXISTING_INSTANCES || true
          aws ec2 wait instance-terminated --instance-ids $EXISTING_INSTANCES || true
        fi
        
        echo "Cleanup completed"

    - name: Force cleanup all related resources
      run: |
        echo "Performing comprehensive cleanup of all related resources..."
        
        # Cleanup security groups
        SG_NAME="${{ env.INSTANCE_IDENTIFIER }}-sg"
        SG_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=$SG_NAME" --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null || echo "None")
        if [ "$SG_ID" != "None" ] && [ "$SG_ID" != "" ]; then
          echo "Deleting security group $SG_ID..."
          aws ec2 delete-security-group --group-id "$SG_ID" || true
        fi
        
        # Cleanup CloudWatch log groups
        LOG_GROUP="/aws/ec2/${{ env.INSTANCE_IDENTIFIER }}"
        if aws logs describe-log-groups --log-group-name-prefix "$LOG_GROUP" --query 'logGroups[0].logGroupName' --output text 2>/dev/null | grep -q "$LOG_GROUP"; then
          echo "Deleting log group $LOG_GROUP..."
          aws logs delete-log-group --log-group-name "$LOG_GROUP" || true
        fi
        
        echo "✓ Comprehensive cleanup completed"

  deploy:
    runs-on: ubuntu-latest
    name: Deploy EC2 and Configure Admin Application
    needs: prepare
    outputs:
      instance_id: ${{ steps.deploy_ec2.outputs.instance_id }}
      instance_ip: ${{ steps.deploy_ec2.outputs.instance_ip }}
      security_group_id: ${{ steps.deploy_ec2.outputs.security_group_id }}
      admin_url: ${{ steps.deploy_ec2.outputs.admin_url }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ github.event.inputs.aws_region }}

    - name: Wait for cleanup completion
      run: |
        echo "Waiting 30 seconds for AWS resource cleanup to propagate..."
        sleep 30

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.6.6
        terraform_wrapper: false

    - name: Terraform Init
      working-directory: infra/aws_admin
      run: terraform init

    - name: Terraform Plan
      working-directory: infra/aws_admin
      run: |
        terraform plan \
          -var="instance_identifier=${{ env.INSTANCE_IDENTIFIER }}" \
          -var="aws_region=${{ github.event.inputs.aws_region }}" \
          -var="instance_type=${{ github.event.inputs.instance_type }}" \
          -var="domain_name=${{ github.event.inputs.domain_name }}" \
          -var="key_pair_name=${{ secrets.EC2_KEY_PAIR }}" \
          -var="elastic_ip_allocation_id=${{ secrets.EC2_ELASTIC_IP_ALLOCATION_ID }}" \
          -var="db_host=${{ secrets.DB_HOST }}" \
          -var="db_port=${{ secrets.DB_PORT }}" \
          -var="db_user=${{ secrets.DB_USER }}" \
          -var="db_password=${{ secrets.DB_PASSWORD }}" \
          -var="admin_default_user=${{ secrets.ADMIN_DEFAULT_USER }}" \
          -var="admin_default_email=${{ secrets.ADMIN_DEFAULT_EMAIL }}" \
          -var="admin_default_password=${{ secrets.ADMIN_DEFAULT_PASSWORD }}" \
          -var="smtp_host=${{ secrets.SMTP_HOST }}" \
          -var="smtp_port=${{ secrets.SMTP_PORT }}" \
          -var="smtp_user=${{ secrets.SMTP_USER }}" \
          -var="smtp_password=${{ secrets.SMTP_PASSWORD }}" \
          -var="smtp_secure=${{ secrets.SMTP_SECURE }}"

    - name: Import existing resources if they exist
      working-directory: infra/aws_admin
      run: |
        # Create import helper script
        cat > import_existing.sh << 'EOF'
        #!/bin/bash
        set +e  # Don't exit on errors for imports
        
        # Import security group if exists
        SG_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=${{ env.INSTANCE_IDENTIFIER }}-sg" --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null || echo "None")
        if [ "$SG_ID" != "None" ] && [ "$SG_ID" != "" ]; then
          echo "Importing security group: $SG_ID"
          terraform import \
            -var="instance_identifier=${{ env.INSTANCE_IDENTIFIER }}" \
            -var="aws_region=${{ github.event.inputs.aws_region }}" \
            -var="instance_type=${{ github.event.inputs.instance_type }}" \
            -var="domain_name=${{ github.event.inputs.domain_name }}" \
            -var="key_pair_name=${{ secrets.EC2_KEY_PAIR }}" \
            -var="elastic_ip_allocation_id=${{ secrets.EC2_ELASTIC_IP_ALLOCATION_ID }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="admin_default_user=${{ secrets.ADMIN_DEFAULT_USER }}" \
            -var="admin_default_email=${{ secrets.ADMIN_DEFAULT_EMAIL }}" \
            -var="admin_default_password=${{ secrets.ADMIN_DEFAULT_PASSWORD }}" \
            -var="smtp_host=${{ secrets.SMTP_HOST }}" \
            -var="smtp_port=${{ secrets.SMTP_PORT }}" \
            -var="smtp_user=${{ secrets.SMTP_USER }}" \
            -var="smtp_password=${{ secrets.SMTP_PASSWORD }}" \
            -var="smtp_secure=${{ secrets.SMTP_SECURE }}" \
            aws_security_group.axialy_admin "$SG_ID"
        fi
        
        # Import log group if exists
        LOG_GROUP="/aws/ec2/${{ env.INSTANCE_IDENTIFIER }}"
        if aws logs describe-log-groups --log-group-name-prefix "$LOG_GROUP" --query 'logGroups[0].logGroupName' --output text 2>/dev/null | grep -q "$LOG_GROUP"; then
          echo "Importing log group: $LOG_GROUP"
          terraform import \
            -var="instance_identifier=${{ env.INSTANCE_IDENTIFIER }}" \
            -var="aws_region=${{ github.event.inputs.aws_region }}" \
            -var="instance_type=${{ github.event.inputs.instance_type }}" \
            -var="domain_name=${{ github.event.inputs.domain_name }}" \
            -var="key_pair_name=${{ secrets.EC2_KEY_PAIR }}" \
            -var="elastic_ip_allocation_id=${{ secrets.EC2_ELASTIC_IP_ALLOCATION_ID }}" \
            -var="db_host=${{ secrets.DB_HOST }}" \
            -var="db_port=${{ secrets.DB_PORT }}" \
            -var="db_user=${{ secrets.DB_USER }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}" \
            -var="admin_default_user=${{ secrets.ADMIN_DEFAULT_USER }}" \
            -var="admin_default_email=${{ secrets.ADMIN_DEFAULT_EMAIL }}" \
            -var="admin_default_password=${{ secrets.ADMIN_DEFAULT_PASSWORD }}" \
            -var="smtp_host=${{ secrets.SMTP_HOST }}" \
            -var="smtp_port=${{ secrets.SMTP_PORT }}" \
            -var="smtp_user=${{ secrets.SMTP_USER }}" \
            -var="smtp_password=${{ secrets.SMTP_PASSWORD }}" \
            -var="smtp_secure=${{ secrets.SMTP_SECURE }}" \
            aws_cloudwatch_log_group.axialy_admin "$LOG_GROUP"
        fi
        
        # Import EC2 instance if exists
        EXISTING_INSTANCES=$(aws ec2 describe-instances \
          --filters "Name=tag:Name,Values=${{ env.INSTANCE_IDENTIFIER }}" "Name=instance-state-name,Values=running,pending,stopping,stopped" \
          --query 'Reservations[].Instances[].InstanceId' --output text)
        if [ -n "$EXISTING_INSTANCES" ]; then
          for instance_id in $EXISTING_INSTANCES; do
            echo "Importing EC2 instance: $instance_id"
            terraform import \
              -var="instance_identifier=${{ env.INSTANCE_IDENTIFIER }}" \
              -var="aws_region=${{ github.event.inputs.aws_region }}" \
              -var="instance_type=${{ github.event.inputs.instance_type }}" \
              -var="domain_name=${{ github.event.inputs.domain_name }}" \
              -var="key_pair_name=${{ secrets.EC2_KEY_PAIR }}" \
              -var="elastic_ip_allocation_id=${{ secrets.EC2_ELASTIC_IP_ALLOCATION_ID }}" \
              -var="db_host=${{ secrets.DB_HOST }}" \
              -var="db_port=${{ secrets.DB_PORT }}" \
              -var="db_user=${{ secrets.DB_USER }}" \
              -var="db_password=${{ secrets.DB_PASSWORD }}" \
              -var="admin_default_user=${{ secrets.ADMIN_DEFAULT_USER }}" \
              -var="admin_default_email=${{ secrets.ADMIN_DEFAULT_EMAIL }}" \
              -var="admin_default_password=${{ secrets.ADMIN_DEFAULT_PASSWORD }}" \
              -var="smtp_host=${{ secrets.SMTP_HOST }}" \
              -var="smtp_port=${{ secrets.SMTP_PORT }}" \
              -var="smtp_user=${{ secrets.SMTP_USER }}" \
              -var="smtp_password=${{ secrets.SMTP_PASSWORD }}" \
              -var="smtp_secure=${{ secrets.SMTP_SECURE }}" \
              aws_instance.axialy_admin "$instance_id"
          done
        fi
        
        set -e  # Re-enable exit on errors
        EOF
        
        chmod +x import_existing.sh
        ./import_existing.sh || echo "Import completed with some resources already managed"

    - name: Terraform Apply
      id: deploy_ec2
      working-directory: infra/aws_admin
      run: |
        terraform apply -auto-approve \
          -var="instance_identifier=${{ env.INSTANCE_IDENTIFIER }}" \
          -var="aws_region=${{ github.event.inputs.aws_region }}" \
          -var="instance_type=${{ github.event.inputs.instance_type }}" \
          -var="domain_name=${{ github.event.inputs.domain_name }}" \
          -var="key_pair_name=${{ secrets.EC2_KEY_PAIR }}" \
          -var="elastic_ip_allocation_id=${{ secrets.EC2_ELASTIC_IP_ALLOCATION_ID }}" \
          -var="db_host=${{ secrets.DB_HOST }}" \
          -var="db_port=${{ secrets.DB_PORT }}" \
          -var="db_user=${{ secrets.DB_USER }}" \
          -var="db_password=${{ secrets.DB_PASSWORD }}" \
          -var="admin_default_user=${{ secrets.ADMIN_DEFAULT_USER }}" \
          -var="admin_default_email=${{ secrets.ADMIN_DEFAULT_EMAIL }}" \
          -var="admin_default_password=${{ secrets.ADMIN_DEFAULT_PASSWORD }}" \
          -var="smtp_host=${{ secrets.SMTP_HOST }}" \
          -var="smtp_port=${{ secrets.SMTP_PORT }}" \
          -var="smtp_user=${{ secrets.SMTP_USER }}" \
          -var="smtp_password=${{ secrets.SMTP_PASSWORD }}" \
          -var="smtp_secure=${{ secrets.SMTP_SECURE }}"

        echo "instance_id=$(terraform output -raw instance_id)" >> $GITHUB_OUTPUT
        echo "instance_ip=$(terraform output -raw instance_ip)" >> $GITHUB_OUTPUT
        echo "security_group_id=$(terraform output -raw security_group_id)" >> $GITHUB_OUTPUT
        echo "admin_url=$(terraform output -raw admin_url)" >> $GITHUB_OUTPUT

    - name: Wait for instance to be ready
      run: |
        echo "Waiting for EC2 instance to be running..."
        aws ec2 wait instance-running --instance-ids ${{ steps.deploy_ec2.outputs.instance_id }}
        echo "EC2 instance is running"

    - name: Deploy application to EC2
          env:
            INSTANCE_IP: ${{ steps.deploy_ec2.outputs.instance_ip }}
          run: |
            echo "Deploying Axialy Admin application to EC2 instance..."
            
            # Setup SSH agent and add passphrase-protected key
            eval $(ssh-agent -s)
            echo "${{ secrets.EC2_SSH_PRIVATE_KEY }}" > /tmp/ec2_key.pem
            chmod 600 /tmp/ec2_key.pem
            
            # Add key to ssh-agent with passphrase
            export DISPLAY=:0.0
            echo "${{ secrets.EC2_SSH_PASSPHRASE }}" | SSH_ASKPASS=/bin/echo setsid ssh-add /tmp/ec2_key.pem
            
            # Wait for SSH to be available
            echo "Waiting for SSH to be available..."
            for i in {1..60}; do
              if ssh -o StrictHostKeyChecking=no -o ConnectTimeout=10 ec2-user@$INSTANCE_IP "echo 'SSH ready'" 2>/dev/null; then
                echo "SSH is ready"
                break
              fi
              echo "SSH not ready, waiting... (attempt $i/60)"
              sleep 15
            done
            
            # Copy application files to EC2
            scp -o StrictHostKeyChecking=no -r axialy-admin-product/ ec2-user@$INSTANCE_IP:~/
            
            # Execute deployment on EC2
            ssh -o StrictHostKeyChecking=no ec2-user@$INSTANCE_IP << 'REMOTE_COMMANDS'
            
            # Update system and install packages - FINAL FIX for Amazon Linux 2023
            sudo dnf update -y
            sudo dnf install -y \
              httpd \
              php \
              php-cli \
              php-fpm \
              php-mysqlnd \
              php-zip \
              php-xml \
              php-mbstring \
              php-curl \
              php-gd \
              php-opcache \
              mariadb105 \
              unzip \
              wget \
              curl
            
            # Enable mod_headers module for Apache
            echo "LoadModule headers_module modules/mod_headers.so" | sudo tee -a /etc/httpd/conf/httpd.conf
            
            # Configure PHP for production
            sudo tee /etc/php.ini > /dev/null << 'PHP_CONFIG'
            [PHP]
            memory_limit = 256M
            upload_max_filesize = 50M
            post_max_size = 50M
            max_execution_time = 300
            max_input_time = 300
            session.gc_maxlifetime = 14400
            session.cookie_secure = 1
            session.cookie_httponly = 1
            session.use_only_cookies = 1
            expose_php = Off
            display_errors = Off
            log_errors = On
            error_log = /var/log/php-errors.log
            date.timezone = UTC
            PHP_CONFIG
            
            # Start and enable services
            sudo systemctl start httpd
            sudo systemctl enable httpd
            sudo systemctl start php-fpm
            sudo systemctl enable php-fpm
            
            # Configure Apache virtual host
            sudo tee /etc/httpd/conf.d/axialy-admin.conf > /dev/null << 'APACHE_CONFIG'
            <VirtualHost *:80>
                DocumentRoot /var/www/html/axialy-admin
                ServerName admin.axialy.com
                DirectoryIndex index.php admin_login.php
                
                <Directory /var/www/html/axialy-admin>
                    Options -Indexes +FollowSymLinks
                    AllowOverride All
                    Require all granted
                    
                    # Security headers
                    Header always set X-Content-Type-Options nosniff
                    Header always set X-Frame-Options DENY
                    Header always set X-XSS-Protection "1; mode=block"
                    Header always set Strict-Transport-Security "max-age=31536000; includeSubDomains"
                    Header always set Referrer-Policy "strict-origin-when-cross-origin"
                </Directory>
                
                # Hide sensitive files
                <FilesMatch "\.(env|log|ini)$">
                    Require all denied
                </FilesMatch>
                
                # PHP handling
                <FilesMatch \.php$>
                    SetHandler "proxy:unix:/run/php-fpm/www.sock|fcgi://localhost"
                </FilesMatch>
                
                # Logging
                ErrorLog /var/log/httpd/axialy-admin-error.log
                CustomLog /var/log/httpd/axialy-admin-access.log combined
            </VirtualHost>
            APACHE_CONFIG
            
            # Deploy application files
            sudo mkdir -p /var/www/html/axialy-admin
            sudo cp -r ~/axialy-admin-product/* /var/www/html/axialy-admin/
            
            # Create .htaccess for additional security
            sudo tee /var/www/html/axialy-admin/.htaccess > /dev/null << 'HTACCESS'
            # Security headers
            <IfModule mod_headers.c>
                Header always set X-Content-Type-Options nosniff
                Header always set X-Frame-Options DENY
                Header always set X-XSS-Protection "1; mode=block"
            </IfModule>
            
            # Prevent access to sensitive files
            <FilesMatch "\.(env|log|ini|conf)$">
                Order allow,deny
                Deny from all
            </FilesMatch>
            
            # Directory protection
            <FilesMatch "^\.">
                Order allow,deny
                Deny from all
            </FilesMatch>
            
            # PHP error handling
            php_flag display_errors Off
            php_flag log_errors On
            php_value error_log /var/log/httpd/php-errors.log
            HTACCESS
            
            # Set proper permissions
            sudo chown -R apache:apache /var/www/html/axialy-admin
            sudo chmod -R 755 /var/www/html/axialy-admin
            sudo chmod 600 /var/www/html/axialy-admin/.env
            
            # Create log directories
            sudo mkdir -p /var/log/axialy-admin
            sudo chown apache:apache /var/log/axialy-admin
            
            # Test database connection
            echo "Testing database connection..."
            php -r "
            require_once '/var/www/html/axialy-admin/includes/AdminDBConfig.php';
            use Axialy\AdminConfig\AdminDBConfig;
            try {
                \$pdo = AdminDBConfig::getInstance()->getPdo();
                echo 'Database connection successful!' . PHP_EOL;
            } catch (Exception \$e) {
                echo 'Database connection failed: ' . \$e->getMessage() . PHP_EOL;
                exit(1);
            }
            "
            
            # Restart services
            sudo systemctl restart httpd
            sudo systemctl restart php-fpm
            
            # Verify services are running
            sudo systemctl status httpd --no-pager
            sudo systemctl status php-fpm --no-pager
            
            echo "✓ Application deployment completed successfully!"
            
            REMOTE_COMMANDS
            
            # Clean up ssh-agent and temporary files
            if [ -n "$SSH_AGENT_PID" ]; then
              ssh-agent -k
            fi
            rm -f /tmp/ec2_key.pem

    - name: Test application deployment
      env:
        INSTANCE_IP: ${{ steps.deploy_ec2.outputs.instance_ip }}
        ADMIN_URL: ${{ steps.deploy_ec2.outputs.admin_url }}
      run: |
        echo "Testing application deployment..."
        
        # Wait a moment for services to fully start
        sleep 10
        
        # Test HTTP response
        echo "Testing HTTP response..."
        HTTP_STATUS=$(curl -s -o /dev/null -w "%{http_code}" "$ADMIN_URL" || echo "000")
        
        if [ "$HTTP_STATUS" = "200" ]; then
          echo "✓ Application is responding correctly (HTTP $HTTP_STATUS)"
        else
          echo "⚠ Application response status: HTTP $HTTP_STATUS"
          echo "This may be normal if DNS/domain setup is still needed"
        fi
        
        # Test if application loads correctly
        echo "Testing application content..."
        if curl -s "$ADMIN_URL" | grep -q "Admin Login"; then
          echo "✓ Admin login page is loading correctly"
        else
          echo "⚠ Admin login page content issue detected"
        fi

    - name: Save deployment info as repository secrets
      env:
        GH_TOKEN: ${{ secrets.GH_PAT }}
        INSTANCE_ID: ${{ steps.deploy_ec2.outputs.instance_id }}
        INSTANCE_IP: ${{ steps.deploy_ec2.outputs.instance_ip }}
        ADMIN_URL: ${{ steps.deploy_ec2.outputs.admin_url }}
      run: |
        if [ -z "$GH_TOKEN" ]; then
          echo "::warning::GH_PAT secret not set. Cannot update repository secrets automatically."
          echo "Please manually add these deployment details as repository secrets:"
          echo "- ADMIN_INSTANCE_ID: $INSTANCE_ID"
          echo "- ADMIN_INSTANCE_IP: $INSTANCE_IP"
          echo "- ADMIN_URL: $ADMIN_URL"
          exit 0
        fi

        gh secret set ADMIN_INSTANCE_ID --body "$INSTANCE_ID"
        gh secret set ADMIN_INSTANCE_IP --body "$INSTANCE_IP"
        gh secret set ADMIN_URL --body "$ADMIN_URL"
        echo "✓ Deployment info saved as repository secrets"

    - name: Display deployment summary
      env:
        INSTANCE_ID: ${{ steps.deploy_ec2.outputs.instance_id }}
        INSTANCE_IP: ${{ steps.deploy_ec2.outputs.instance_ip }}
        ADMIN_URL: ${{ steps.deploy_ec2.outputs.admin_url }}
      run: |
        echo "=================================================="
        echo "AWS Axialy Admin deployed successfully!"
        echo "=================================================="
        echo "Instance ID: $INSTANCE_ID"
        echo "Public IP: $INSTANCE_IP"
        echo "Region: ${{ github.event.inputs.aws_region }}"
        echo "Instance Type: ${{ github.event.inputs.instance_type }}"
        echo "=================================================="
        echo ""
        echo "Access URLs:"
        echo "- Admin Interface: $ADMIN_URL"
        echo ""
        echo "Default Admin Credentials:"
        echo "- Username: ${{ secrets.ADMIN_DEFAULT_USER }}"
        echo "- Email: ${{ secrets.ADMIN_DEFAULT_EMAIL }}"
        echo "- Password: [Use ADMIN_DEFAULT_PASSWORD secret]"
        echo ""
        echo "Database Connection:"
        echo "- Connected to: ${{ secrets.DB_HOST }}"
        echo "- Databases: axialy_admin, axialy_ui"
        echo ""
        echo "Next Steps:"
        echo "1. Access the admin interface using the URL above"
        echo "2. Complete any initial setup prompts"
        echo "3. Change default password after first login"
        echo "4. Configure DNS if using custom domain"
        echo ""
        echo "Security Notes:"
        echo "- SSL/HTTPS should be configured for production"
        echo "- Monitor application logs in /var/log/httpd/"
        echo "- Regular security updates recommended"
        echo "=================================================="

  cleanup:
    runs-on: ubuntu-latest
    name: Cleanup Temporary Resources
    needs: deploy
    if: always()
    
    steps:
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ github.event.inputs.aws_region }}

    - name: Cleanup temporary resources
      run: |
        echo "Performing cleanup of temporary resources..."
        
        # Note: In this deployment, we keep the main resources (EC2, Security Groups)
        # but clean up any temporary files or failed deployments
        
        # Cleanup any failed/orphaned instances without proper tags
        echo "Checking for orphaned resources..."
        
        # This is a placeholder for any cleanup logic
        # In the database deployment, we cleaned up temporary EC2 instances
        # For admin deployment, the EC2 instance IS the final product
        
        echo "✓ Cleanup completed (no temporary resources to clean)"

    - name: Final status report
      run: |
        if [ "${{ needs.deploy.result }}" == "success" ]; then
          echo "🎉 Axialy Admin deployment completed successfully!"
          echo "Admin interface '${{ env.INSTANCE_IDENTIFIER }}' is ready for use."
        else
          echo "⚠️  Deployment encountered issues. Check the deploy job logs."
        fi
